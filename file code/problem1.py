# -*- coding: utf-8 -*-
"""problem1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Exa40txaDbeWgwFTexPUuHy0eBUU1I8w

問題1   CIFAR-10のデータセットに対してより高い精度を実現するプログラム(PyTorch)を作成せよ。ただし、プログラムは第10回の講義資料のプログラム(もしくはLab Work (4)で作成したプログラム)を改良して作成せよ。その「プログラム」と「実行結果」およびそれらに関する「解説」をwordファイルにまとめて提出せよ。また、プログラムのソースコード(.py)も提出せよ。
例: VGG16, ハイパーパラメータ調整など

期待される精度: 75%以上

Problem 1: Write a program (PyTorch) that achieves higher accuracy on the CIFAR-10 data set. The program should be an improved version of the program in the 10th lecture (or the program you wrote in Lab Work (4)). Submit the “Program”, its “Execution Results”, and an “Explanation” of them in a word file.  Also submit the source code (.py) of the program.
Example: VGG16, hyperparameter tuning, etc.

Expected accuracy: 75% or more

Group 35

- Lê Hải Nam - 21522357
- Trần Nguyễn Yến Nhi - 21522429
- Nguyễn Thị Cẩm Ly - 21522315

To create a PyTorch program that achieves higher accuracy on the CIFAR-10 dataset, we'll focus on improving the model architecture and training process. Here's a step-by-step outline of what the improved program will include:

Data Loading and Preprocessing:

Use data augmentation techniques such as random crops, flips, and normalization.
Create data loaders for training and validation datasets.
Model Architecture:

Use a deeper convolutional neural network (CNN) architecture compared to the basic ones used previously.
Utilize techniques like batch normalization to stabilize and accelerate training.
Employ dropout to reduce overfitting.
Loss Function and Optimizer:

Use the Cross-Entropy Loss, suitable for multi-class classification tasks like CIFAR-10.
Choose an optimizer like Adam, which adapts learning rates for each parameter.
Training Loop:

Train the model for more epochs with a learning rate scheduler to adjust learning rates dynamically.
Monitor and log training/validation losses and accuracy.
Save the model checkpoint with the best validation accuracy.
Evaluation:

Evaluate the final model on the test dataset to measure its performance accurately.

# Import Library
"""

!pip install torch

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn.functional as F
import torchvision as tv
import torch.optim as optim
import torch.nn as nn
import matplotlib.pyplot as plt
import PIL.ImageOps
import requests
from PIL import Image

"""# Data preprocess"""

#Convert PyTorch tensor into a numpy array suitable for display as an image
def im_convert(tensor):
  image = tensor.cpu().clone().detach().numpy()
  #Transposes the dimensions of the image tensor.
  image = image.transpose(1, 2, 0)
  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))
  image = image.clip(0, 1)
  return image

# Define transformations for training and testing data
transform_train = tv.transforms.Compose([
    # Resize images to 50x50 pixels
    tv.transforms.Resize((50,50)),
     # Randomly flip images horizontally
    tv.transforms.RandomHorizontalFlip(),
     # Convert images to PyTorch tensors
    tv.transforms.ToTensor(),
])

transform_test = tv.transforms.Compose([
    # Convert images to PyTorch tensors
    tv.transforms.ToTensor(),
    # Resize images to 50x50 pixels
    tv.transforms.Resize((50,50)),
])

# Download and load CIFAR-10 dataset
train_dataset = tv.datasets.CIFAR10(root="./", train=True,transform=transform_train,download=True)
test_dataset = tv.datasets.CIFAR10(root="./", train=False,transform=transform_test,download=True)

# Create data loaders for training and testing datasets
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)

# Visualize a batch of training images
dataiter = iter(train_loader)
images, labels = next(dataiter)
fig = plt.figure(figsize=(25, 4))

for idx in np.arange(20):
  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
  plt.imshow(im_convert(images[idx]))
  ax.set_title(labels[idx].item())

"""# Create VGG model"""

'''This will create an instance of the VGG class with the specified VGG16 architecture, ready to be trained and evaluated on your dataset.
Adjustments to vgg_name can allow to instantiate VGG models with different configurations (e.g., VGG11, VGG19) by passing their respective configuration lists (VGG11, VGG19, etc.).'''

VGG16 =  [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']

class VGG(nn.Module):
    def __init__(self, vgg_name):
        super(VGG, self).__init__()
        self.features = self._make_layers(VGG16)
        self.classifier = nn.Linear(512, 10)

    def forward(self, x):
        out = self.features(x)
        out = out.view(out.size(0), -1)
        out = self.classifier(out)
        return out

    def _make_layers(self, cfg):
        layers = []
        in_channels = 3
        for x in VGG16:
            if x == 'M':
                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
            else:
                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),
                           nn.BatchNorm2d(x),
                           nn.ReLU(inplace=True)]
                in_channels = x
        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]
        return nn.Sequential(*layers)

"""# Train model"""

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

def train():
  chart_x = []
  chart_y = []
  optimizer = torch.optim.Adam(model.parameters())
  for epoch in range(EPOCH):
    loss = 0
    for images, labels in train_loader:
      images = images.to(DEVICE)
      labels = labels.to(DEVICE)
      optimizer.zero_grad()
      y = model(images)
      batchloss = F.cross_entropy(y, labels)
      batchloss.backward()
      optimizer.step()
      loss = loss + batchloss.item()

    print("epoch", epoch, ": loss", loss)
    chart_x.append(epoch)
    chart_y.append(loss)

  plt.style.use('seaborn-whitegrid')
  plt.xlabel("epoch")
  plt.ylabel("loss")
  plt.plot(chart_x,chart_y, color = "red")

"""# Test model"""

def test():
  total = len(test_loader.dataset)
  correct = 0
  # Set the model to evaluation mode
  model.eval()

  for images, labels in test_loader:
    images = images.to(DEVICE)
    labels = labels.to(DEVICE)
    y = model(images)
    pred_labels = y.max(dim=1)[1]
    correct= correct + (pred_labels == labels).sum()

  '''Computes total correct predictions (correct).
    Calculates accuracy (accuracy = correct / total) and prints it as a percentage.
    Outputs the number of correct predictions and total number of samples for verification.'''
  print("correct: ", correct.item())
  print("total: ", total)
  print("accuracy: ", (correct.item() / float(total)))

"""# Result"""

#EPOCHS = [10, 20, 50]   List of epochs to iterate over

EPOCH = 10
print('\n' + 'total EPOCH:', EPOCH)
model = VGG('VGG16').to(DEVICE)
train()
test()


EPOCH = 20
print('\n' + 'total EPOCH:', EPOCH)
model = VGG('VGG16').to(DEVICE)
train()
test()


EPOCH = 50
print('\n' + 'total EPOCH:', EPOCH)
model = VGG('VGG16').to(DEVICE)
train()
test()

dataiter = iter(test_loader)
images, labels = next(dataiter)
images = images.to(DEVICE)
labels = labels.to(DEVICE)
output = model(images)
_, preds = torch.max(output, 1)

fig = plt.figure(figsize=(25, 4))
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

for idx in np.arange(20):
  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
  plt.imshow(im_convert(images[idx]))
  ax.set_title("{} ({})".format(str(classes[preds[idx].item()]), str(classes[labels[idx].item()])), color=("green" if preds[idx]==labels[idx] else "red"))

url = 'https://cdn1.tuoitre.vn/zoom/600_315/471584752817336320/2023/10/24/nd231024-may-bay-e175-cua-alaska-airlines-1698116590932432834797-91-0-615-1000-crop-16981166580631667974716.jpg'
# Download the image from the URL
response = requests.get(url, stream = True)

img = Image.open(response.raw)
img = transform_test(img)
plt.imshow(im_convert(img))

image = img.to(DEVICE).unsqueeze(0)
output = model(image)
_, pred = torch.max(output, 1)
print(classes[pred.item()])